{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'christmasbreak'\n",
    "browser = webdriver.Chrome('/Users/matt/Downloads/chromedriver')\n",
    "browser.get('https://twitter.com/hashtag/' + tag + '?lang=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "\n",
    "def scrape(start, end):\n",
    "    print('scrolling: {}-{}'.format(start, end))\n",
    "    Pagelength = browser.execute_script(\"window.scrollTo({}, {});\".format(start, end))\n",
    "    source = browser.page_source\n",
    "    data=bs(source, 'html.parser')\n",
    "    body = data.find('body')\n",
    "    script = body.findAll('div', {'data-permalink-path': True})\n",
    "    for div in script:\n",
    "        status = div.get('data-permalink-path')\n",
    "        links.append('https://www.twitter.com{}'.format(status))\n",
    "    \n",
    "    time.sleep(5)\n",
    "    if (end < 50000):\n",
    "        scrape(start + 3000, end + 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling: 0-6000\n",
      "scrolling: 3000-9000\n",
      "scrolling: 6000-12000\n",
      "scrolling: 9000-15000\n",
      "scrolling: 12000-18000\n",
      "scrolling: 15000-21000\n",
      "scrolling: 18000-24000\n",
      "scrolling: 21000-27000\n",
      "scrolling: 24000-30000\n",
      "scrolling: 27000-33000\n",
      "scrolling: 30000-36000\n",
      "scrolling: 33000-39000\n",
      "scrolling: 36000-42000\n",
      "scrolling: 39000-45000\n",
      "scrolling: 42000-48000\n",
      "scrolling: 45000-51000\n"
     ]
    }
   ],
   "source": [
    "scrape(0, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 tweets\n"
     ]
    }
   ],
   "source": [
    "print('Found {} tweets'.format(len(links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        page = urlopen(links[i]).read()\n",
    "        data=bs(page, 'html.parser')\n",
    "        body = data.find('body')\n",
    "        user = body.find('b', {'class': 'u-linkComplex-target'})\n",
    "        location = body.find('span', {'class': 'ProfileHeaderCard-locationText u-dir'})\n",
    "        content = body.find('p', {'class': 'tweet-text'})\n",
    "        tweetDetails = body.find('div', {'class': 'tweet-details-fixer'})\n",
    "        timeStamp = tweetDetails.find('span').find('span').text\n",
    "        tweet = {\n",
    "            'user': '@{}'.format(user.text),\n",
    "            'location': location.text.strip(),\n",
    "            'tweet': content.text,\n",
    "            'timeStamp': timeStamp\n",
    "        }\n",
    "        x = pd.DataFrame.from_dict(json_normalize(tweet), orient='columns') \n",
    "        x = x[['user', 'location', 'tweet', 'timeStamp']]\n",
    "        result = result.append(x) \n",
    "    except:\n",
    "        np.nan\n",
    "\n",
    "result.index = range(len(result.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped 20 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>timeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BridportMan</td>\n",
       "      <td>Bridport</td>\n",
       "      <td>We'll be on Christmas break from December 16th...</td>\n",
       "      <td>5:54 AM - 27 Nov 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@HILeicesterCity</td>\n",
       "      <td>Leicester, England</td>\n",
       "      <td>Plan your pre-Christmas break to Leicester now...</td>\n",
       "      <td>8:08 AM - 27 Nov 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@afaranwide</td>\n",
       "      <td></td>\n",
       "      <td>Sunset over Phu Quoc, Vietnam.\\n\\nLook out for...</td>\n",
       "      <td>2:41 AM - 27 Nov 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sarah___Mary</td>\n",
       "      <td>South Wales</td>\n",
       "      <td>When you realise you only have to survive one ...</td>\n",
       "      <td>11:21 PM - 26 Nov 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@EduClickAfrica</td>\n",
       "      <td>Centre, Cameroon</td>\n",
       "      <td>Our #Techlab offers affordable #excursion expe...</td>\n",
       "      <td>12:05 AM - 25 Nov 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user            location  \\\n",
       "0      @BridportMan            Bridport   \n",
       "1  @HILeicesterCity  Leicester, England   \n",
       "2       @afaranwide                       \n",
       "3     @Sarah___Mary         South Wales   \n",
       "4   @EduClickAfrica    Centre, Cameroon   \n",
       "\n",
       "                                               tweet               timeStamp  \n",
       "0  We'll be on Christmas break from December 16th...   5:54 AM - 27 Nov 2019  \n",
       "1  Plan your pre-Christmas break to Leicester now...   8:08 AM - 27 Nov 2019  \n",
       "2  Sunset over Phu Quoc, Vietnam.\\n\\nLook out for...   2:41 AM - 27 Nov 2019  \n",
       "3  When you realise you only have to survive one ...  11:21 PM - 26 Nov 2019  \n",
       "4  Our #Techlab offers affordable #excursion expe...  12:05 AM - 25 Nov 2019  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.drop_duplicates()\n",
    "print('scraped {} tweets'.format(len(result)))\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
