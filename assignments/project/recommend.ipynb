{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "df = pd.read_csv('output_combined_30k_locations.csv', index_col='id')\n",
    "df['countries'] = (df['countries']\n",
    "                   .fillna('[]')\n",
    "                   .map(lambda v: v.replace('\\'', '\\\"'))\n",
    "                   .map(lambda v: json.loads(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('photo', 13537),\n",
       " ('private', 7865),\n",
       " ('beach', 6644),\n",
       " ('nature', 6610),\n",
       " ('city', 6456),\n",
       " ('tour', 2981),\n",
       " ('family', 2196),\n",
       " ('gift', 1808),\n",
       " ('happy', 1679),\n",
       " ('time', 1640)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_words = {'com', 'twitter', 'travel', 'vacation', 'holiday', \n",
    "              'destination', 'flight', 'deal', '00', 'u', \n",
    "              'english', 'bali', 'weekend', 'thanksgiving', 'christmas', \n",
    "              'trip', 'best', 'new', 'news', 'london', \n",
    "              'day', 'sale', 'traveller', 'book'}\n",
    "\n",
    "same_map = {\n",
    "    'photo': ['pic', 'travelblogger', 'blog', 'photography', 'travelgram', \n",
    "              'travelphotography', 'beautiful', 'photographytour'],\n",
    "    'private': ['getaway', 'escape'],\n",
    "    'nature': ['experience', 'adventure', 'explore', 'outdoor'],\n",
    "    'beach': ['cruise', 'resort', 'island', 'sunset'],\n",
    "    'city': ['hotel', 'hoteldeals', 'luxury'],\n",
    "    'tour': ['guide']\n",
    "}\n",
    "\n",
    "same_inv_map = {word: root for root, words in same_map.items() for word in words}\n",
    "\n",
    "def splitter(data):\n",
    "    words = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', data.lower()).split()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "def convert_same(text):\n",
    "    return [(same_inv_map[word] if word in same_inv_map else word) for word in splitter(text)]\n",
    "\n",
    "def wordCount(data):\n",
    "    filtered = [w for w in convert_same(' '.join(data['text'])) if w not in stop_words|drop_words]\n",
    "    return Counter(filtered).most_common()\n",
    "\n",
    "wordCount(df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(set(df['countries'].sum()), columns=['countries']).set_index('countries')\n",
    "data['tweets'] = 'temp-value'\n",
    "data['tweets'] = data['tweets'].map(lambda _: set())\n",
    "\n",
    "for tweet_id, row in df.iterrows():\n",
    "    for country in row['countries']:\n",
    "        data.loc[country]['tweets'].add(tweet_id)\n",
    "\n",
    "feature_words = ['photo', 'private', 'city', 'nature', 'beach', 'tour', 'family']\n",
    "\n",
    "feature_pos_di = dict(zip(feature_words, list(range(len(feature_words)))))\n",
    "\n",
    "def vectorize_tokens(tokens):\n",
    "    vector = np.zeros(len(feature_words))\n",
    "    for index, feature_word in enumerate(feature_words):\n",
    "        for token in tokens:\n",
    "            if token == feature_word:\n",
    "                vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "def aggregate(tweets): return sum([tweet_ids_to_tokens[tweet] for tweet in tweets])\n",
    "\n",
    "tweet_ids_to_tokens = df['text'].map(convert_same).map(vectorize_tokens).to_dict()\n",
    "\n",
    "data['vectors'] = data['tweets'].map(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countries\n",
       "Italy        373.0\n",
       "Australia    320.0\n",
       "Spain        307.0\n",
       "Thailand     278.0\n",
       "Canada       266.0\n",
       "Mexico       265.0\n",
       "France       237.0\n",
       "Jamaica      206.0\n",
       "Turkey       173.0\n",
       "Malaysia     158.0\n",
       "Name: vectors, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['China', 'India'], inplace=True)\n",
    "\n",
    "data['vectors'].map(sum).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(series, query):\n",
    "    query_vector = series.loc[query]\n",
    "    matrix = pd.DataFrame(series.tolist()).values\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=1+5, algorithm='auto', metric='cosine').fit(matrix)\n",
    "    distances, similar_items = nn.kneighbors([query_vector])\n",
    "\n",
    "    similar_item_names = series.iloc[similar_items[0]].index.tolist()\n",
    "    \n",
    "    return similar_item_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan', 'Morocco', 'Italy', 'Romania', 'Georgia']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(data['vectors'], 'Australia')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
