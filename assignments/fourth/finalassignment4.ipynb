{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment 4: Is a Picture Worth a Thousand Words? </center>\n",
    "## <center> Matt Viteri, Abhilash Gupta, Stephen Darasimi Oluwaniyi, Colin Chu </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-479b3093831e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import vision\n",
    "import os\n",
    "import nltk\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords');\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"APAD-DARASIMI-8c1a66d445ac.json\"\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0. \n",
    "\n",
    "On Instagram, choose the National Geographic (natgeo) page (do not use hashtags). Write a\n",
    "scraper or use the Web Scraper to extract \n",
    "- Image URLs (do not extract video URLs, it may end up costing you a lot of money to run analytics on video)\n",
    "- Post caption (the text description of a post)\n",
    "- Number of likes\n",
    "- Number of comments (You donâ€™t need actual comments for this assignment)\n",
    "- Scrape around 400-500 image posts. \n",
    "\n",
    "Using the image URLs, obtain image labels from Google Vision cloud (you will have to create an\n",
    "account with Google to get your credentials as a json file, though the first $300 are free, which\n",
    "should be more than plenty for this assignment)\n",
    "- You will need to write a script to access the Google Vision API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See scraper in attached file\n",
    "data = pd.read_csv(\"output.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a metric for engagement by using a weighted sum of # likes and # comments. \n",
    "- First normalize # likes and # comments such that they both have values between 0 and 1. You can scale the # likes by dividing by the maximum # likes (for a post) in your data and do the same for # comments, so that # likes and comments will be in the range [0,1]\n",
    "- Now create an <b> engagement score = .4*# likes (normalized) + .6*# comments (normalized) </b>\n",
    "- Define High (1) and Low (0) engagement based on whether the engagement score is above or below the median value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Likes & Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Likes = data['likes']\n",
    "Norm_Likes = (Likes-Likes.min())/(Likes.max()-Likes.min())\n",
    "print(Norm_Likes.head())\n",
    "print(\"The range of Norm_Likes is between %i and %i\"%(Norm_Likes.max(),Norm_Likes.min()))\n",
    "print()\n",
    "Comments = data['comments']\n",
    "Norm_Comments = (Comments-Comments.min())/(Comments.max()-Comments.min())\n",
    "print(Norm_Comments.head())\n",
    "print(\"\\n The range of Norm_Comments is between %i and %i\"%(Norm_Comments.max(),Norm_Comments.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Engagement_Score = 0.4*Norm_Likes + 0.6*Norm_Comments\n",
    "print(Engagement_Score.head())\n",
    "Engagement_Median = Engagement_Score.median()\n",
    "print(\"The Engagement_Median is %f\"% Engagement_Median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Engagement [ 1 or 0 ] base on Engagement Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Engagement = Engagement_Score.apply(lambda x: 1 if x >= Engagement_Median else 0)\n",
    "print(Engagement.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Norm_Likes'] = Norm_Likes\n",
    "data['Norm_Comments'] = Norm_Comments\n",
    "data['Engagement_Score'] = Engagement_Score\n",
    "data['Engagement'] = Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('TaskA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the image labels\n",
    "\n",
    "def detect_labels_uri(uri):\n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    image.source.image_uri = uri\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    label_description = []\n",
    "    for label in labels:\n",
    "        label_description.append(label.description)\n",
    "    return label_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TaskA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image_labels\"] = df[\"media_url\"].apply(lambda x: detect_labels_uri(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['type','media_url','image_labels','caption','likes','comments','Norm_Likes','Norm_Comments','Engagement_Score','Engagement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('image_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B\n",
    "\n",
    "Run a logistic regression with Engagement (binary) as the dependent variable, and the\n",
    "image labels as independent variables. \n",
    "- What is the accuracy (show the confusion matrix)?\n",
    "- What accuracy do you get by using the post caption words as the independent variables instead of image labels?\n",
    "- Finally, what accuracy do you get by combining the image labels and post captions and using them as independent variables? What can you conclude from your analysis?\n",
    "- Note: Doing a word frequency analysis and word replacement on the image labels as well as captions will increase the accuracy of prediction. Needless to say, TF-IDF scores should be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C\n",
    "Perform topic modeling (LDA) on the image labels. Choose an appropriate number of topics. \n",
    "- You may want to start with 5, but adjust the number up or down depending on the word distributions you get\n",
    "- LDA should produce two outputs: \n",
    "    - A file showing which words load on which topics\n",
    "    - A file showing topic weights for each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_TOPICS = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('image_labels.csv')\n",
    "df['image_labels'] = df['image_labels'].apply(lambda l: json.loads(l.replace('\\'', '\\\"')))\n",
    "\n",
    "texts = df['image_labels'].tolist()\n",
    "id2word = gensim.corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=NUMBER_OF_TOPICS, \n",
    "                                           random_state=9,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=25,\n",
    "                                           passes=100,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.DataFrame([(topic, [id2word[t[0]] for t in lda_model.get_topic_terms(topic)]) for topic in range(NUMBER_OF_TOPICS)])\n",
    "c1.to_csv('TaskCi.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_weights(corpus):\n",
    "    result = pd.DataFrame(0, columns=range(NUMBER_OF_TOPICS), index=range(len(corpus)))\n",
    "    for index, scores in result.iterrows():\n",
    "        for score in lda_model.get_document_topics(corpus[index]):\n",
    "            result.iloc[index, score[0]] = score[1]\n",
    "    return result\n",
    "\n",
    "c2 = get_topic_weights(corpus)\n",
    "    \n",
    "c2.to_csv('TaskCii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_weights(df):\n",
    "    corpus1 = [id2word.doc2bow(text) for text in df['image_labels'].tolist()]\n",
    "    weights1 = get_topic_weights(corpus1)\n",
    "    return weights1.sum()/weights1.shape[0]\n",
    "\n",
    "df1, df2, df3, df4 = np.array_split(df.sort_values(by='Engagement_Score', ascending=False), 4)\n",
    "\n",
    "scores1 = get_avg_weights(df1)\n",
    "scores4 = get_avg_weights(df4)\n",
    "data = zip(range(NUMBER_OF_TOPICS), c1[1], scores1.tolist(), scores4.tolist(), (scores1-scores4).tolist())\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "end_result = pd.DataFrame(data, columns=['Topics', 'Words', 'Avg. top quartile weight', 'Avg. bottom quartile weight', 'Difference'])\n",
    "end_result.set_index('Topics').sort_values(by='Difference', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D \n",
    "\n",
    "What advice would you give National Geographic if it wants to increase engagement on its Instagram page based on your findings in Tasks B and C? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
